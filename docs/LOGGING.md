# Logging Guide for Bridge.dev

This document describes the logging infrastructure and usage patterns for Bridge.dev.

## Overview

Bridge.dev uses structured logging with correlation IDs for request tracing. The logging system is configured differently for development and production environments:

- **Development**: Human-readable format with correlation IDs in brackets
- **Production**: JSON format for log aggregation and analysis

## Correlation IDs

Every request automatically receives a unique correlation ID that:
- Is generated by `CorrelationIDMiddleware` (or extracted from `X-Correlation-ID` header)
- Is added to all log records for that request
- Is included in response headers as `X-Correlation-ID`
- Enables tracing requests across services and async tasks

## Basic Usage

### In Views

```python
from apps.common.logging_utils import get_logger, log_request, log_error
import logging

logger = get_logger(__name__)

class MyView(APIView):
    def get(self, request):
        # Log request with correlation ID
        log_request(logger, request)
        
        try:
            # Your code here
            logger.info('Processing request', extra={
                'user_id': str(request.user.id),
                'workspace_id': request.workspace_id,
            })
            return Response({'status': 'success'})
        except Exception as e:
            log_error(logger, e, request)
            return Response({'error': str(e)}, status=500)
```

### In Models

```python
from apps.common.logging_utils import get_logger
import logging

logger = get_logger(__name__)

class MyModel(models.Model):
    def save(self, *args, **kwargs):
        logger.debug(f'Saving {self.__class__.__name__} {self.id}')
        super().save(*args, **kwargs)
```

### In Celery Tasks

```python
from apps.common.logging_utils import get_logger, with_correlation_id
from celery import shared_task

logger = get_logger(__name__)

@shared_task
def my_task(correlation_id=None, **kwargs):
    # Set correlation ID for task logging
    with with_correlation_id(correlation_id or 'task-123'):
        logger.info('Starting task', extra=kwargs)
        # Task logic here
        logger.info('Task completed')
```

## Logging Utilities

### `get_logger(name, correlation_id=None)`

Get a logger instance with correlation ID support.

```python
from apps.common.logging_utils import get_logger

logger = get_logger(__name__)
logger.info('This log will include correlation ID if available')
```

### `log_request(logger, request, level=logging.INFO)`

Log request information with correlation ID and context.

```python
from apps.common.logging_utils import log_request

log_request(logger, request)
# Logs: [correlation-id] INFO GET /api/v1/workflows/
```

### `log_error(logger, error, request=None, level=logging.ERROR)`

Log errors with correlation ID and context.

```python
from apps.common.logging_utils import log_error

try:
    # Code that might fail
    pass
except Exception as e:
    log_error(logger, e, request)
```

### `with_correlation_id(correlation_id)`

Context manager to set correlation ID in logging context.

```python
from apps.common.logging_utils import with_correlation_id

with with_correlation_id('abc-123'):
    logger.info('This log will have correlation_id=abc-123')
```

### `@log_function_call(logger)`

Decorator to log function calls with correlation ID.

```python
from apps.common.logging_utils import log_function_call

@log_function_call(logger)
def my_function():
    # Function calls are automatically logged
    pass
```

## Log Levels

Use appropriate log levels:

- **DEBUG**: Detailed information for debugging
- **INFO**: General informational messages
- **WARNING**: Warning messages for potential issues
- **ERROR**: Error messages for exceptions
- **CRITICAL**: Critical errors requiring immediate attention

## Best Practices

1. **Always use correlation IDs**: They enable request tracing across services
2. **Include context**: Add user_id, workspace_id, and other relevant context
3. **Use structured logging**: Include extra fields for better log analysis
4. **Don't log sensitive data**: Never log passwords, tokens, or PII
5. **Use appropriate log levels**: Don't use ERROR for expected conditions

## Example: Complete View with Logging

```python
from rest_framework.views import APIView
from rest_framework.response import Response
from apps.common.logging_utils import get_logger, log_request, log_error
import logging

logger = get_logger(__name__)

class WorkflowView(APIView):
    def post(self, request):
        # Log incoming request
        log_request(logger, request, level=logging.INFO)
        
        try:
            # Extract context
            user_id = str(request.user.id) if request.user.is_authenticated else None
            workspace_id = request.workspace_id
            
            logger.info('Creating workflow', extra={
                'user_id': user_id,
                'workspace_id': workspace_id,
                'workflow_name': request.data.get('name'),
            })
            
            # Create workflow
            workflow = Workflow.objects.create(...)
            
            logger.info('Workflow created', extra={
                'workflow_id': str(workflow.id),
                'user_id': user_id,
                'workspace_id': workspace_id,
            })
            
            return Response({'id': str(workflow.id)}, status=201)
            
        except ValidationError as e:
            logger.warning('Validation error', extra={
                'errors': str(e),
                'user_id': user_id,
            })
            return Response({'error': str(e)}, status=400)
            
        except Exception as e:
            log_error(logger, e, request)
            return Response({'error': 'Internal server error'}, status=500)
```

## Correlation ID Propagation

Correlation IDs are automatically:
- Generated for each request
- Added to log records
- Included in response headers
- Available via `request.correlation_id`

To propagate to async tasks (Celery), pass the correlation ID:

```python
from apps.common.logging_utils import with_correlation_id

@shared_task
def process_workflow(workflow_id, correlation_id=None):
    with with_correlation_id(correlation_id):
        logger.info(f'Processing workflow {workflow_id}')
        # Task logic
```

## Production Considerations

In production:
- Logs are formatted as JSON for log aggregation tools
- Correlation IDs are included in all log entries
- Log levels are set to INFO or higher
- Sensitive data is automatically redacted (implement as needed)

## Troubleshooting

If correlation IDs are missing:
1. Ensure `CorrelationIDMiddleware` is in `MIDDLEWARE` settings
2. Check that middleware order is correct (should be early in the list)
3. Verify logging formatter includes correlation ID

If logs aren't appearing:
1. Check log level configuration
2. Verify handlers are configured correctly
3. Check that logger name matches configuration

